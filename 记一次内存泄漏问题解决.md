# 20190506 生产订单组件响应慢问题

## 问题描述
1. 订单组件响应时间大幅增加，非正常响应时间。 甚至于日志中出现 readTimeOut 的ERROR日志
2. 故障时好时坏，不是100%每次都能重现
3. 故障发生时，该容器已运行12天



## 问题定位

#### 怀疑
根据问题描述，初步怀疑问题是由于内存泄漏导致。

#### 检查GC日志
检查GC日志如下,频繁发生FULLGC， 且每次执行完GC后，释放内存数量极少，
 1. 平均每2秒执行一次FULLGC
 2. OC(老年代总容量)261962K(255.82Mb)，OU(老年代已使用容量)261963kb(255.82MB)，老年代可使用仅仅生0.18M
```
2019-05-06T14:54:47.399+0800: 1626821.737: [Full GC (Ergonomics) [PSYoungGen: 245721K->241947K(253952K)] [ParOldGen: 261962K->261962K(262144K)] 507684K->503910K(516096K), [Metaspace: 155570K->155566K(1189888K)], 1.1401951 secs] [Times: user=3.22 sys=0.00, real=1.14 secs]
2019-05-06T14:54:48.540+0800: 1626822.879: Total time for which application threads were stopped: 1.1423290 seconds, Stopping threads took: 0.0001460 seconds
2019-05-06T14:54:48.704+0800: 1626823.043: [Full GC (Ergonomics) [PSYoungGen: 245760K->241519K(253952K)] [ParOldGen: 261962K->261962K(262144K)] 507722K->503482K(516096K), [Metaspace: 155566K->155566K(1189888K)], 0.7160701 secs] [Times: user=2.01 sys=0.00, real=0.71 secs]
2019-05-06T14:54:49.420+0800: 1626823.759: Total time for which application threads were stopped: 0.7175655 seconds, Stopping threads took: 0.0001972 seconds
2019-05-06T14:54:54.590+0800: 1626828.929: [Full GC (Ergonomics) [PSYoungGen: 245760K->241519K(253952K)] [ParOldGen: 261962K->261962K(262144K)] 507722K->503482K(516096K), [Metaspace: 155566K->155566K(1189888K)], 0.7964936 secs] [Times: user=2.06 sys=0.00, real=0.80 secs]
2019-05-06T14:54:55.387+0800: 1626829.726: Total time for which application threads were stopped: 0.7986541 seconds, Stopping threads took: 0.0002320 seconds
2019-05-06T14:54:55.563+0800: 1626829.902: [Full GC (Ergonomics) [PSYoungGen: 245760K->241519K(253952K)] [ParOldGen: 261962K->261962K(262144K)] 507722K->503482K(516096K), [Metaspace: 155566K->155566K(1189888K)], 0.7866745 secs] [Times: user=2.08 sys=0.00, real=0.78 secs]
2019-05-06T14:54:56.350+0800: 1626830.689: Total time for which application threads were stopped: 0.7883045 seconds, Stopping threads took: 0.0001781 seconds
2019-05-06T14:55:00.352+0800: 1626834.691: Total time for which application threads were stopped: 0.0011686 seconds, Stopping threads took: 0.0001539 seconds
2019-05-06T14:55:01.482+0800: 1626835.821: [Full GC (Ergonomics) [PSYoungGen: 245760K->241519K(253952K)] [ParOldGen: 261962K->261962K(262144K)] 507722K->503482K(516096K), [Metaspace: 155566K->155566K(1189888K)], 0.8941622 secs] [Times: user=2.06 sys=0.02, real=0.89 secs]
2019-05-06T14:55:02.376+0800: 1626836.715: Total time for which application threads were stopped: 0.8956285 seconds, Stopping threads took: 0.0001647 seconds
2019-05-06T14:55:02.549+0800: 1626836.888: [Full GC (Ergonomics) [PSYoungGen: 245760K->241519K(253952K)] [ParOldGen: 261962K->261962K(262144K)] 507722K->503482K(516096K), [Metaspace: 155566K->155566K(1189888K)], 0.9047407 secs] [Times: user=2.05 sys=0.01, real=0.91 secs]
```

#### 现场保留

执行jmap 备份现场
```
[root@42906abe7735 bin]# jmap -dump:live,format=b,file=dump.hprof 31
Dumping heap to /dapeng-container/bin/dump.hprof ...
Heap dump file created
[root@42906abe7735 bin]# exit
exit
[isuwang@SZ-WEB-M ~]$ docker cp basic-services:/dapeng-container/bin/dump.hprof .
```


#### 紧急恢复服务
重启容易并检查容器内存状况，确保生产业务正常运行.
```
[isuwang@SZ-WEB-S ~]$ docker restart basic-services
[isuwang@SZ-WEB-S ~]$ docker exec -it basic-services bash
[root@688911624aa0 bin]# jps
33 Bootstrap
249 Jps
[root@688911624aa0 bin]# jstat -gc 33 2000 10
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
8192.0 8192.0 3366.3  0.0   245760.0 26661.1   262144.0   50957.1   105944.0 104440.9 13312.0 12984.7     12    0.300   4      0.608    0.908
8192.0 8192.0 3366.3  0.0   245760.0 96074.5   262144.0   50957.1   105944.0 104440.9 13312.0 12984.7     12    0.300   4      0.608    0.908
8192.0 8192.0 3366.3  0.0   245760.0 167114.4  262144.0   50957.1   105944.0 104440.9 13312.0 12984.7     12    0.300   4      0.608    0.908
8192.0 8192.0 3366.3  0.0   245760.0 199791.3  262144.0   50957.1   105944.0 104440.9 13312.0 12984.7     12    0.300   4      0.608    0.908
8192.0 8192.0  0.0   2835.1 245760.0  8004.8   262144.0   52029.2   107736.0 105917.0 13568.0 13150.8     13    0.306   4      0.608    0.914
8192.0 8192.0  0.0   2835.1 245760.0 68750.8   262144.0   52029.2   107736.0 105917.0 13568.0 13150.8     13    0.306   4      0.608    0.914
```
#### 内存分析
使用 eclipse 的 mat 工具进行内存分析,可以发现确实存在内存泄漏的嫌疑，点击进入报告内容，可以发现，泄漏发生的地点位于，com.aliyun.oss.common.comm.IdleConnectionReaper。该类属于aliyun的对象存储sdk中的类。 
![leak report][1]
![leak detail][2]



### 问题解决
#### 问题确认
查找阿里云相关论坛等发现[问题原因][3]。如下代码实例，单例模式写法存在问题。
```java
OSSClient client = ClientHelper.getOssClient

public class ClientHelper {
     private static OSSClient ossClient;

    public static OSSClient getOssClient() {
        if (ossClient == null)
            return new OSSClient(endpoint, accessKeyId, accessKeySecret);
        else return ossClient;
    }
}
```

#### 解决方案
使用正确的单例模式写法。
```java
OSSClient client = ClientHelper.getOssClient

public class ClientHelper {

    private static class OssClientHolder {
        private static OSSClient client = new OSSClient(endpoint, accessKeyId, accessKeySecret);
    }
    
    public static OSSClient getOssClient() {
        return OssClientHolder.client;
    }
}
```


  [1]: https://upload-images.jianshu.io/upload_images/8665921-ee47734011323373.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/839/format/webp
  [2]: https://upload-images.jianshu.io/upload_images/8665921-c0d1319c67f4d567.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240
  [3]: https://github.com/aliyun/aliyun-oss-java-sdk/issues/126
